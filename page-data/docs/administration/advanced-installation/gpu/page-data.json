{"componentChunkName":"component---src-templates-create-pages-js","path":"/docs/administration/advanced-installation/gpu","result":{"data":{"markdownRemark":{"html":"<p>Open Data Hub has support for accessing NVIDIA GPUs from Jupyter notebooks. Currently,\nthe Open Data Hub team has verified that JupyterHub can successfully access the GPU in OpenShift 3.11 clusters.\nOpenShift 4.x GPU enablement is still in development. These instructions will be updated as soon as it is available.</p>\n<h3>Prerequisites</h3>\n<ul>\n<li>\n<p>OpenShift cluster with GPU(s) enabled</p>\n<ul>\n<li>Enabling GPUs in OpenShift 3.11 is outside of the scope of Open Data Hub. The document <a href=\"https://github.com/zvonkok/origin-ci-gpu/blob/release-3.11/doc/How%20to%20use%20GPUs%20with%20DevicePlugin%20in%20OpenShift%203.11%20.pdf\">How to use GPUs with DevicePlugin in OpenShift 3.11</a> can provide guidance, but is not official.</li>\n<li>\n<p>Enabling GPUs in OpenShift 4.x can be achieved by deploying Node Feature Discovery (NFD) Operator and NVIDIA GPU Operator.</p>\n<p>The <a href=\"https://github.com/openshift/cluster-nfd-operator\">Node Feature Discovery</a> operator is responsible for discovering and labeling hardware (GPU(s) in this case) features available on each node.\nThe <a href=\"https://github.com/NVIDIA/gpu-operator\">NVIDIA GPU Operator</a> will setup and install the necessary drivers to enable the use of GPU(s) as compute resource.</p>\n<ol>\n<li>Deploy the Node Feature Discovery operator using the OpenShift OperatorHub WebUI.\nThe blog on <a href=\"https://blog.openshift.com/creating-a-gpu-enabled-node-with-openshift-4-2-in-amazon-ec2\">Creating a GPU-enabled node with OpenShift 4.2 in Amazon EC2</a> has a \"Deploy the Node Feature Discovery Operator\" section that demonstrates how to deploy the NFD operator and create a <code>NodeFeatureDiscovery</code> custom resource</li>\n<li>\n<p>Before deploying the NVIDIA GPU Operator confirm that all of the nodes with GPUs have the appropriate hardware labels.</p>\n<pre><code>$ oc describe node &#x3C;GPU NODE NAME> -o json \n\nName:    ip-10-0-137-200.ec2.internal\nRoles:   worker\nLabels:  beta.kubernetes.io/arch=amd64\n          beta.kubernetes.io/instance-type=p2.xlarge\n          beta.kubernetes.io/os=linux\n          failure-domain.beta.kubernetes.io/region=us-east-1\n          failure-domain.beta.kubernetes.io/zone=us-east-1a\n          feature.node.kubernetes.io/cpu-cpuid.ADX=true\n          feature.node.kubernetes.io/cpu-cpuid.AESNI=true\n          feature.node.kubernetes.io/cpu-cpuid.AVX=true\n          feature.node.kubernetes.io/cpu-cpuid.AVX2=true\n          feature.node.kubernetes.io/cpu-cpuid.FMA3=true\n          feature.node.kubernetes.io/cpu-cpuid.HLE=true\n          feature.node.kubernetes.io/cpu-cpuid.RTM=true\n          feature.node.kubernetes.io/cpu-hardware_multithreading=true\n          feature.node.kubernetes.io/cpu-pstate.turbo=true\n          feature.node.kubernetes.io/kernel-selinux.enabled=true\n          feature.node.kubernetes.io/kernel-version.full=4.18.0-147.3.1.el8_1.x86_64\n          feature.node.kubernetes.io/kernel-version.major=4\n          feature.node.kubernetes.io/kernel-version.minor=18\n          feature.node.kubernetes.io/kernel-version.revision=0\n          feature.node.kubernetes.io/pci-1013.present=true\n          feature.node.kubernetes.io/pci-10de.present=true\n          feature.node.kubernetes.io/pci-1d0f.present=true\n          feature.node.kubernetes.io/storage-nonrotationaldisk=true\n          feature.node.kubernetes.io/system-os_release.ID=rhcos\n          feature.node.kubernetes.io/system-os_release.VERSION_ID=4.3\n          feature.node.kubernetes.io/system-os_release.VERSION_ID.major=4\n          feature.node.kubernetes.io/system-os_release.VERSION_ID.minor=3\n          ...\n</code></pre>\n</li>\n<li>Deploy the NVIDIA GPU operator using the OpenShift OperatorHub WebUI.\nThe guide <a href=\"https://docs.nvidia.com/datacenter/kubernetes/openshift-on-gpu-install-guide/index.html\">OpenShift on GPU install</a> has a <a href=\"https://docs.nvidia.com/datacenter/kubernetes/openshift-on-gpu-install-guide/index.html#openshift-gpu-support\">GPU support</a> section covering all the steps to deploy the NVIDIA GPU operator.</li>\n<li>\n<p>Once the Special Resource Operator finishes the installation of the appropriate drivers, you should see the number of gpus available as a resource on the GPU enabled nodes.</p>\n<pre><code>$ oc get node &#x3C;GPU NODE NAME> -o json | jq .status.allocatable\n{\n  \"cpu\": \"3500m\",\n  \"hugepages-1Gi\": \"0\",\n  \"hugepages-2Mi\": \"0\",\n  \"memory\": \"15804984Ki\",\n  \"pods\": \"250\",\n  \"nvidia.com/gpus\": \"1\"\n}\n</code></pre>\n</li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n<h3>Configuring the JupyterHub component</h3>\n<p>To properly configure the <code>aicoe-jupytherhub</code> component to use GPUs, 2 things must be done</p>\n<ol>\n<li>Deploy GPU Compatible Jupyter Notebook Images by setting <code>notebook_images.deploy_cuda_notebooks: True</code>.</li>\n<li>Configure JupyterHub Server to spawn user pods with GPU access by setting <code>gpu_mode</code> to empty/<code>null</code>, <code>selinux</code>, or <code>privileged</code></li>\n</ol>\n<p>These settings will deploy a set of <code>BuildConfigs</code> which prepare <strong>CUDA enabled Python s2i images</strong> which are then used for building <code>s2i-tensorflow-notebook-gpu</code> image available in JupyterHub Spawner UI. This image has Tensorflow GPU pre-installed and enables users to leverage GPUs available in a cluster with the Tensorflow library.</p>\n<p>The build chain template can be found upstream at <a href=\"https://github.com/thoth-station/tensorflow-build-s2i/tree/master/cuda\">https://github.com/thoth-station/tensorflow-build-s2i/tree/master/cuda</a></p>\n<h4>OpenShift 4.x</h4>\n<p>Leave the <code>gpu_mode</code> empty or set it to <code>null</code>.</p>\n<pre><code class=\"language-yaml\">aicoe-jupyterhub:\n    gpu_mode: \"\"\n    notebook_images:\n        deploy_cuda_notebooks: True\n</code></pre>\n<h4>OpenShift 3.11 (Standard)</h4>\n<p>If the configuration of the cluster is based on the documentation <a href=\"https://github.com/zvonkok/origin-ci-gpu/blob/release-3.11/doc/How%20to%20use%20GPUs%20with%20DevicePlugin%20in%20OpenShift%203.11%20.pdf\">How to use GPUs with DevicePlugin in OpenShift 3.11</a>, set gpu_mode to value <code>selinux</code></p>\n<pre><code class=\"language-yaml\">aicoe-jupyterhub:\n    gpu_mode: \"selinux\"\n    notebook_images:\n        deploy_cuda_notebooks: True\n</code></pre>\n<h4>OpenShift 3.11 (Other)</h4>\n<p>In the case GPU enablement in the cluster is configured differently, containers may be required to run in privileged mode to gain access to GPUs. In this case set <code>gpu_mode</code> to value <code>privileged</code></p>\n<pre><code class=\"language-yaml\">aicoe-jupyterhub:\n    gpu_mode: \"privileged\"\n    notebook_images:\n        deploy_cuda_notebooks: True\n</code></pre>\n<h3>Verifying GPU Availability</h3>\n<p>To spawn a Jupyter Notebook with GPU support, set the <code>GPU</code> field to a number greater than 0.  From inside the notebook, run the following command to verify it's availability.</p>\n<pre><code class=\"language-python\">import tensorflow as tf\ntf.test.is_gpu_available()\n</code></pre>\n<h4>Additional resources</h4>\n<ul>\n<li><a href=\"https://blog.openshift.com/how-to-use-gpus-with-deviceplugin-in-openshift-3-10\">How to use GPUs with DevicePlugin in OpenShift 3.10</a></li>\n<li><a href=\"https://docs.openshift.com/container-platform/3.11/dev_guide/device_plugins.html\">OpenShift 3.11 - Using Device Plug-ins</a></li>\n<li><a href=\"https://kubernetes.io/docs/tasks/manage-gpus/scheduling-gpus\">Kubernetes GPU Documentation</a></li>\n<li><a href=\"https://docs.openshift.com/container-platform/3.11/admin_guide/manage_scc.html\">OpenShift 3.11 Cluster Administration / Managing Security Context Constraints</a></li>\n<li><a href=\"https://github.com/AICoE/jupyterhub-ocp-oauth\">JupyterHub deployment using OpenShift OAuth authenticator</a></li>\n</ul>\n<p>{% include next-link.html label=\"Architecture\" url=\"/docs/architecture.html\" %}</p>"}},"pageContext":{"permalink":"/docs/administration/advanced-installation/gpu"}},"staticQueryHashes":["1804438722"]}