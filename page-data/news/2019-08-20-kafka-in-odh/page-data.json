{"componentChunkName":"component---src-templates-create-pages-js","path":"/news/2019-08-20-kafka-in-odh","result":{"data":{"markdownRemark":{"html":"<h2>Apache Kafka</h2>\n<p><img src=\"../../assets/img/posts/2019-08-20-kafka-in-odh/apache_kafka.png\" alt=\"alt text\"></p>\n<p>The Open Data Hub is a reference architecture running on OpenShift that incorporates a variety of open source projects to function as an ML-as-a-service platform. Given the huge amounts of data to be ingested and processed, it's crucial to have a reliable streaming platform. To solve this problem we use Apache Kafka.</p>\n<p>Apache Kafka is an open-source stream-processing software platform. It is used for building real-time data pipelines and streaming apps. It is horizontally scalable, fault-tolerant, wicked fast, and runs in production in thousands of companies.</p>\n<p>Apache Kafka is a distributed streaming platform. What exactly does that mean?\nA streaming platform has three key capabilities:</p>\n<ol>\n<li>Publish and subscribe to streams of records, similar to a message queue or enterprise messaging system.</li>\n<li>Store streams of records in a fault-tolerant durable way.</li>\n<li>Process streams of records as they occur.</li>\n</ol>\n<p>Kafka is generally used for two broad classes of applications:</p>\n<p>Building real-time streaming data pipelines that reliably get data between systems or applications\nBuilding real-time streaming applications that transform or react to the streams of data</p>\n<h2>Strimzi Operator</h2>\n<p><img src=\"../../assets/img/posts/2019-08-20-kafka-in-odh/strimzi.png\" alt=\"alt text\" title=\"Strimzi\"></p>\n<p><a href=\"https://strimzi.io/\">Strimzi</a> is based on Apache Kafka, a popular platform for streaming data delivery and processing. Strimzi makes it easy to run Apache Kafka on Kubernetes.</p>\n<p>Strimzi provides three operators:</p>\n<ol>\n<li>Cluster Operator\nResponsible for deploying and managing Apache Kafka clusters running on a Kubernetes cluster.</li>\n<li>Topic Operator\nResponsible for managing Kafka topics within a Kafka cluster running on a Kubernetes cluster.</li>\n<li>User Operator\nResponsible for managing Kafka users within a Kafka cluster running on a Kubernetes cluster.</li>\n</ol>\n<h2>Monitoring</h2>\n<p>Kafka deployed usind ODH Operator comes pre-configured to expose metrics out of the box which are scraped using Prometheus and Visualized using Grafana. This gives us a holistic view of the Kafka cluster's health and performance.</p>\n<p><img src=\"../../assets/img/posts/2019-08-20-kafka-in-odh/kafka_metrics.png\" alt=\"alt text\" title=\"Kafka Monitoring\"></p>\n<h2>Sample Use Cases</h2>\n<ol>\n<li>Data Ingestion: Internally we have a Kafka deployment for ingesting data and back it up to Elasticsearch and Ceph S3 for analysis using Logstash and s3 Connector. We have 3 Kafka and 3 zookeeper Brokers of 10 Tb each backed by Persistent Volumes with a peak throughput of around 20k messages per second and a sustained rate of ~12k messages per second.</li>\n<li>Data Streaming: For credit monitoring we have a kafka deployment which ingests credit data as a producer in near-real time and are consumed and sent to the seldon model-serving layer for risk monitoring and fraud detection.</li>\n</ol>"}},"pageContext":{"permalink":"/news/2019-08-20-kafka-in-odh"}},"staticQueryHashes":["1804438722"]}