{"componentChunkName":"component---src-templates-create-pages-js","path":"/news/2019-12-16-odh-release-0.5-blog","result":{"data":{"markdownRemark":{"html":"<h2>What is included?</h2>\n<p>Open Data Hub 0.5.0 includes many new tools that are essential to a comprehensive AI/ML end-to-end platform. Open Data Hub is a meta-operator that can be installed on Openshift Container Platform 3.11 and 4.x.</p>\n<p>The following is a list of tools added to Open Data Hub in this release:</p>\n<table>\n<thead>\n<tr>\n<th>Technology</th>\n<th>Version</th>\n<th>Category</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>JupyterHub CUDA GPU Images and Notebooks</td>\n<td>3.0.7</td>\n<td>Support for building CUDA GPU Images and GPU Notebook</td>\n</tr>\n<tr>\n<td>Apache <a href=\"https://github.com/apache/incubator-superset\">Superset</a></td>\n<td>0.34.0</td>\n<td>Data Exploration and Visualization Tool</td>\n</tr>\n<tr>\n<td>Data Catalog (<a href=\"https://gethue.com/\">Hue</a>, <a href=\"https://spark.apache.org/docs/latest/sql-distributed-sql-engine.html\">Spark Thrift Server</a>, Hive Metastore)</td>\n<td>Hue 4.4.1 &#x26; Spark Thrift Server 2.4 &#x26; Hive Metastore 1.2.1</td>\n<td>Deployment of Hue, Spark Thrift Server and Hive Metastore to simplify querying data lakes using Spark SQL language</td>\n</tr>\n<tr>\n<td><a href=\"https://argoproj.github.io/argo/\">Argo</a></td>\n<td>2.4.2</td>\n<td>Container native workflow engine</td>\n</tr>\n</tbody>\n</table>\n<p>{:class=\"table table-bordered table-striped\"}</p>\n<p>You can review the release notes for components added in the previous v0.4.0 release <a href=\"https://opendatahub.io/news/2019-09-16/odh-release-0.4-blog.html\">here</a></p>\n<h2>AICoE-JupyterHub CUDA GPU Images and Notebooks</h2>\n<p>AICoE-JupyterHub now has support for accessing NVIDIA GPUs from Jupyter notebooks. In this release, we added </p>\n<ul>\n<li>Documentation on how to <a href=\"https://gitlab.com/opendatahub/opendatahub-operator/blob/v0.5.0/docs/enabling-gpu-aicoe-jupyterhub.adoc\">enable GPUs nodes</a> in your OpenShift cluster</li>\n<li>Support for building CUDA GPU images and notebooks as part of the component deployment process</li>\n</ul>\n<p>You can test these new features by following the Data Engineering and Machine Learning <a href=\"https://gitlab.com/opendatahub/data-engineering-and-machine-learning-workshop\">workshop</a>. The <a href=\"https://gitlab.com/opendatahub/data-engineering-and-machine-learning-workshop/blob/master/source/notebooks/tf-training-serving.ipynb\">tf-training-serving</a> contains a demonstration of how you can create Openshift Jobs to access a cluster GPU.</p>\n<h2>Apache Superset</h2>\n<p>Apache <a href=\"https://github.com/apache/incubator-superset\">Superset</a> is a data exploration and visualization tool. Instructions for deploying and creating an example database &#x26; chart are available in <a href=\"https://gitlab.com/opendatahub/opendatahub-operator/blob/v0.5.0/docs/deploying-superset.adoc\">Deploy Superset Setup</a>.</p>\n<h2>Data Catalog (Tech Preview)</h2>\n<p>The Data Catalog is a set of components with which you can run Data Exploration on your Data Lake. These components are:</p>\n<ul>\n<li><em>Hive Metastore</em> to store metadada information about the Hive tables</li>\n<li><em>Spark SQL Thrift server</em> to expose a ODBC/JDBC endpoint to interact with the Hive Tables</li>\n<li><em>Hue</em> to view S3 object store, connect to Spark SQL Thrift server and run queries, as well as create dashboards.</li>\n</ul>\n<p>For more information on the Data Catalog, please review the Data Catalog <a href=\"https://opendatahub.io/news/2019-12-15/data-catalog-in-odh.html\">announcement</a> and <a href=\"https://opendatahub.io/docs/advanced-tutorials/data-exploration.html\">tutorial</a>. The Data Catalog is currently designated as \"Tech Preview\" as we enable support for additional features available in Hue.</p>\n<h2>Argo</h2>\n<p><a href=\"https://argoproj.github.io/\">Argo</a> has been updated to version 2.4.2. <a href=\"https://argoproj.github.io/\">Argo</a> is an open source container-native workflow engine for orchestrating parallel jobs on Kubernetes.  It is useful for defining workflows using containers, running computer intensive jobs, and orchestrating DAG container pipelines natively on Kubernetes.</p>\n<p>To learn more about deploying Argo in Open Data Hub, please visit <a href=\"https://gitlab.com/opendatahub/opendatahub-operator/blob/master/docs/deploying-argo.adoc\">link</a></p>"}},"pageContext":{"permalink":"/news/2019-12-16-odh-release-0.5-blog"}},"staticQueryHashes":["1804438722"]}