{"componentChunkName":"component---src-templates-create-pages-js","path":"/news/2018-12-04-open-data-hub-overview","result":{"data":{"markdownRemark":{"html":"<h2>What is the Open Data Hub?</h2>\n<p><img src=\"/assets/img/posts/2018-12-04-open-data-hub-overview/Open_Data_Hub_Deployment.png\" alt=\"alt text\" title=\"Open Data Hub\"></p>\n<p>Built on OpenShift, Open Data Hub uses the leading Kubernetes platform to deliver a meta-project that integrates Open Source components into a practical service-oriented AI and ML solution.  Organizations and IT departments can deploy Open Data Hub as a centralized self-service solution for analytic and data science workloads.</p>\n<h2>AI Library</h2>\n<p>Open Data Hub deploys with a set of pre-defined AI models available for use.  Try the services out and get some value out of your data immediately without having to accumulate massive amounts of training data.  Current models available include sentiment analysis, test flake analysis and more.</p>\n<h2>Data Science and ETL Tools</h2>\n<p><img src=\"../../assets/img/posts/2018-12-04-open-data-hub-overview/ds_tools.png\" alt=\"alt text\" title=\"Open Data Hub - Data Science\"></p>\n<p>Data scientists can use familiar tools such as Jupyter notebooks for developing complex algorithms and models.  Frameworks such as numpy, scikit-learn, Tensorflow and more are available for use.</p>\n<p>For data engineers who need to query or process their data, Spark from radanalytics.io is available for use.  If JDBC/ODBC access is required for data stored in S3, Spark Thrift Server comes pre-configured and ready to go.</p>\n<h2>Streaming and Enriching Data</h2>\n<p><img src=\"../../assets/img/posts/2018-12-04-open-data-hub-overview/streaming_tools.png\" alt=\"alt text\" title=\"Open Data Hub - Streaming and Enrichment\"></p>\n<p>Open Data Hub offers numerous services for ingesting data, including Kafka, Logstash, Fluentd and rsyslog.  At the heart of it all is the strimzi.io Kafka streaming platform, which allows data to be ingested and processed at scale.  Kafka applications and logstash micro-services can be used to enrich your inbound data before it lands in storage.</p>\n<h2>Storing Data</h2>\n<p><img src=\"../../assets/img/posts/2018-12-04-open-data-hub-overview/storage_tools.png\" alt=\"alt text\" title=\"Open Data Hub - Storage\"></p>\n<p>Data is the foundational piece of AI, and Red Hat Ceph Object Store is ideal for building your lake of unstructured data.  Cephâ€™s S3 API makes integration with popular big data tools simple and easy.</p>\n<p>If log analysis is more what you need, Open Data Hub provides a deployment of Elasticsearch with Kibana for visualizations.</p>\n<h2>Managing Data</h2>\n<p><img src=\"../../assets/img/posts/2018-12-04-open-data-hub-overview/dm_tools.png\" alt=\"alt text\" title=\"Open Data Hub - Manage Data\"></p>\n<p>Design your data pipelines the Kubernetes way using Argo.  Jobs can be created to train models or transform data.</p>\n<h2>Monitoring Infrastructure</h2>\n<p><img src=\"../../assets/img/posts/2018-12-04-open-data-hub-overview/monitor_tools.png\" alt=\"alt text\" title=\"Open Data Hub - Monitor\"></p>\n<p>Open Data Hub comes standard with Prometheus and Grafana for monitoring the components.  DevOps teams have predefined dashboards to help manage the infrastructure.</p>\n<h2>Community</h2>\n<p>We are an open community that fosters collaboration between organizations, vendors, developers, and academics.  <a href=\"https://gitlab.com/opendatahub\">Join us and contribute</a>!</p>\n<h2>Tools</h2>\n<p><b>Available in Open Data Hub</b></p>\n<ul>\n<li>AI Library</li>\n<li><a href=\"https://ceph.com/ceph-storage/object-storage/\">Ceph Object Storage</a></li>\n<li><a href=\"https://spark.apache.org/\">Spark</a></li>\n<li><a href=\"http://jupyter.org/hub\">JuypyterHub</a></li>\n<li><a href=\"https://jupyter.org/\">Jupyter Notebooks</a></li>\n<li><a href=\"https://www.tensorflow.org/\">Tensorflow</a></li>\n</ul>\n<p><b>Coming Soon to Open Data Hub</b></p>\n<ul>\n<li>Kafka (<a href=\"https://www.redhat.com/en/about/videos/summit-2018-introducing-amq-streams-data-streaming-apache-kafka\">AMQ Streams</a> and <a href=\"http://strimzi.io/\">Strimzi</a>)</li>\n<li><a href=\"https://docs.confluent.io/current/connect/index.html\">Kafka Connect</a></li>\n<li><a href=\"https://spark.apache.org/docs/latest/sql-distributed-sql-engine.html\">Spark Thrift Server</a></li>\n<li><a href=\"https://www.elastic.co/products/elasticsearch\">Elasticsearch</a></li>\n<li><a href=\"https://www.elastic.co/products/logstash\">Logstash</a></li>\n<li><a href=\"https://www.fluentd.org/\">Fluentd</a></li>\n<li><a href=\"https://www.rsyslog.com/\">Rsyslog</a></li>\n<li><a href=\"https://www.elastic.co/products/kibana\">Kibana</a></li>\n<li><a href=\"https://prometheus.io/\">Prometheus</a></li>\n<li><a href=\"https://grafana.com/\">Grafana</a></li>\n<li><a href=\"https://argoproj.github.io/\">Argo</a></li>\n</ul>"}},"pageContext":{"permalink":"/news/2018-12-04-open-data-hub-overview"}},"staticQueryHashes":["1804438722"]}